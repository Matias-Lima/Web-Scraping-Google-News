{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0126f6-8cfc-4ab9-b275-c499e5591ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5fda13-d341-4138-a730-00e4df03b8f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import WebDriverException, NoSuchElementException, TimeoutException\n",
    "import logging\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class WebScraper_NewsGoogle:\n",
    "    def __init__(self, keyword):\n",
    "        self.keyword = keyword\n",
    "        self.driver = None\n",
    "        self.news_data = []\n",
    "        \n",
    "        self.setup_driver()\n",
    "        self.search_for_keyword()\n",
    "        self.click_on_news()\n",
    "\n",
    "    def setup_driver(self):\n",
    "        \n",
    "        chrome_options = webdriver.ChromeOptions()\n",
    "        chrome_options.add_argument(\"--disable-notifications\")\n",
    "        #chrome_options.add_argument(\"--headless\")  # Add this line to run in headless mode\n",
    "        service = Service(executable_path='C:/Users/limam/Documents/Programação/Python/Projetos/Web Scraping/chromedriver.exe')\n",
    "        # Pass the service object to the webdriver\n",
    "        self.driver = webdriver.Chrome(options=chrome_options, service=service) \n",
    "        self.driver.get(\"http://www.google.com/\")\n",
    "        \n",
    "        try:\n",
    "            WebDriverWait(self.driver, 5).until(EC.presence_of_element_located((By.NAME, 'q')))\n",
    "        except WebDriverException:\n",
    "            print(\"Tweets did not appear! Proceeding after timeout\")\n",
    "\n",
    "    def search_for_keyword(self):\n",
    "        \n",
    "        search_box = self.driver.find_element(By.NAME, 'q')\n",
    "        search_box.send_keys(self.keyword)\n",
    "        search_box.submit()\n",
    "\n",
    "    def click_on_news(self):\n",
    "        try:\n",
    "            WebDriverWait(self.driver, 5).until(EC.presence_of_element_located((By.LINK_TEXT, \"Notícias\")))\n",
    "            element = self.driver.find_element(By.LINK_TEXT, \"Notícias\")\n",
    "            element.click()\n",
    "                       \n",
    "        except NoSuchElementException as e:\n",
    "            \n",
    "            WebDriverWait(self.driver, 5).until(EC.presence_of_element_located((By.LINK_TEXT, \"News\")))\n",
    "            element = self.driver.find_element(By.LINK_TEXT, \"News\")\n",
    "            element.click() \n",
    "\n",
    "    def scrape_data(self):\n",
    "        News_data = []\n",
    "        try:\n",
    "            while True:\n",
    "                try:\n",
    "                    # Tente encontrar os resultados de notícias usando o seletor CSS\n",
    "                    try:\n",
    "                        news_results = self.driver.find_elements(By.CSS_SELECTOR, 'div#rso > div > div > div > div')\n",
    "                        for news_div in news_results:   \n",
    "                            try:\n",
    "                                news_item = {}\n",
    "\n",
    "                                try:\n",
    "                                    news_link = news_div.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                                    news_item[\"Link\"] = news_link\n",
    "                                except NoSuchElementException as e:\n",
    "                                    print(\"Link not found:\", e)\n",
    "                                    logging.error(\"Link not found: \" + str(e))\n",
    "                                    news_item[\"Link\"] = None\n",
    "                                    continue  # Continue para o próximo item de notícia\n",
    "\n",
    "                                # Extrair o domínio\n",
    "                                domain_elements = news_div.find_elements(By.CSS_SELECTOR, 'a > div > div > div')\n",
    "\n",
    "                                if len(domain_elements) >= 2:\n",
    "                                    domain = domain_elements[1].text\n",
    "                                    news_item[\"Domain\"] = domain\n",
    "                                else:\n",
    "                                    print(\"Domain not found\")\n",
    "                                    news_item[\"Domain\"] = None\n",
    "\n",
    "                                # Extrair o título\n",
    "                                if len(domain_elements) >= 3:\n",
    "                                    title = domain_elements[2].text\n",
    "                                    news_item[\"Title\"] = title\n",
    "                                else:\n",
    "                                    print(\"Title not found\")\n",
    "                                    news_item[\"Title\"] = None\n",
    "\n",
    "                                # Extrair a descrição\n",
    "                                if len(domain_elements) >= 4:\n",
    "                                    description = domain_elements[3].text\n",
    "                                    news_item[\"Description\"] = description\n",
    "                                else:\n",
    "                                    print(\"Description not found\")\n",
    "                                    news_item[\"Description\"] = None\n",
    "\n",
    "                                # Extrair a data\n",
    "                                if len(domain_elements) >= 5:\n",
    "                                    date = domain_elements[4].text\n",
    "                                    news_item[\"Date\"] = date\n",
    "                                else:\n",
    "                                    try:\n",
    "                                        Date = news_div.find_element(By.CSS_SELECTOR, '#rso > div > div > div.SoaBEf.R24aHf > div > div > a > div > div.iRPxbe > div.OSrXXb.rbYSKb.LfVVr')\n",
    "                                        news_item[\"Date\"] = Date\n",
    "                                    except NoSuchElementException as e:\n",
    "                                        #print(\"Date not found\")\n",
    "                                        news_item[\"Date\"] = None\n",
    "                                        continue  # Continue para o próximo item de notícia\n",
    "                                   \n",
    "\n",
    "\n",
    "                                print(\"Link:\", news_item[\"Link\"])\n",
    "                                print(\"Domain:\", news_item[\"Domain\"])\n",
    "                                print(\"Title:\", news_item[\"Title\"])\n",
    "                                print(\"Description:\", news_item[\"Description\"])\n",
    "                                print(\"Date:\", news_item[\"Date\"])\n",
    "                                print(\"-\" * 50 + \"\\n\\n\" + \"-\" * 50)\n",
    "\n",
    "                                try:\n",
    "                                    News_data.append(news_item)\n",
    "\n",
    "                                except Exception as e:\n",
    "                                    print(\"Error appending news_item to News_data:\", e)\n",
    "                                    logging.error(\"Error appending news_item to News_data: \" + str(e))\n",
    "\n",
    "\n",
    "                            except NoSuchElementException as e:\n",
    "                                print(\"Incomplete news item:\", e)\n",
    "                                logging.error(\"Incomplete news item: \" + str(e))\n",
    "\n",
    "                                try:                                \n",
    "                                    WebDriverWait(self.driver, 5).until(EC.presence_of_element_located((By.ID, \"pnnext\")))\n",
    "                                    elemento_proxima = self.driver.find_element(By.ID, \"pnnext\")\n",
    "                                    #time.sleep(2)\n",
    "                                    elemento_proxima.click()\n",
    "\n",
    "                                except NoSuchElementException:\n",
    "                                    # Tratamento de erro: O botão \"Próxima\" não foi encontrado, indicando o fim das páginas\n",
    "                                    print(\"Não há mais páginas disponíveis.\")\n",
    "\n",
    "\n",
    "                    except NoSuchElementException as e:\n",
    "                        print(\"News results not found:\", e)\n",
    "                        logging.error(\"News results not found: \" + str(e))\n",
    "                        # Sair do loop se os resultados de notícias não forem encontrados\n",
    "\n",
    "                except NoSuchElementException:\n",
    "                    # Tratamento de erro: O elemento \"Próxima\" não foi encontrado, ou seja, não há mais páginas\n",
    "                    print(\"Não há mais páginas disponíveis.\")\n",
    "\n",
    "                # Encontre o elemento \"Próxima\" (ou equivalente) pelo ID ou outro seletor\n",
    "                try:\n",
    "                    elemento_proxima = self.driver.find_element(By.ID, \"pnnext\")\n",
    "                    elemento_proxima.click()\n",
    "\n",
    "                except NoSuchElementException:\n",
    "                    # Tratamento de erro: O botão \"Próxima\" não foi encontrado, indicando o fim das páginas\n",
    "                    print(\"Não há mais páginas disponíveis.\")\n",
    "                    break\n",
    "\n",
    "        except TimeoutException as e:\n",
    "            print(f\"Timeout Exception: {e}\")\n",
    "            logging.error(\"Timeout Exception: \" + str(e))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            logging.error(\"An error occurred: \" + str(e))\n",
    "\n",
    "        #finally:\n",
    "            # Feche o navegador após a conclusão\n",
    "            #driver.quit()\n",
    "\n",
    "        return News_data\n",
    "\n",
    "    def close_driver(self):\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "            print(\"Realizada\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Pronto Para começar!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e524fe-9c93-4663-9faa-c1efa34fff76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_list_10 = []\n",
    "data_list_15 = []\n",
    "data_list_25 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d951e9-62e9-4ae9-a281-ca242c9fad5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keyword = 'Debentures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25214bf6-efb1-4ca5-9899-77da19dc9093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Google_news = WebScraper_NewsGoogle(keyword)\n",
    "News = Google_news.scrape_data()\n",
    "\n",
    "data_list_10.extend(News[:10])\n",
    "data_list_15.extend(News[:15])\n",
    "data_list_25.extend(News[:25])\n",
    "\n",
    "Google_news.close_driver()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
